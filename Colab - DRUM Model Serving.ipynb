{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DRUM - Automated Model Serving Made Easy.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timsetsfire/odsc-ml-drum/blob/main/Colab%20-%20DRUM%20Model%20Serving.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLxOyJ2xMrlL"
      },
      "source": [
        "# DRUM - Automated Model Serving Made Easy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OUbruxUMrlM"
      },
      "source": [
        " We'll get our hands dirty by \n",
        "\n",
        "* Building a simple regression model using Scikit\n",
        "* Using DRUM for Batch Scoring\n",
        "* Using DRUM to get a REST API endpoint\n",
        "* Show a simple example app connected to the REST API\n",
        "* H2O, Keras, XGBoost, and DataRobot\n",
        "* Add a DataRobot remote agent if you are interested in further model monitoring\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykjnP6-ZMrlM"
      },
      "source": [
        "## Build a Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IDgpv8NMs7r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ed45d7-8959-47d4-c6d7-961aff4929f8"
      },
      "source": [
        "!git clone https://github.com/timsetsfire/odsc-ml-drum.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'odsc-ml-drum' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x86AAdVeMjl6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe404b9d-e975-4fbc-dfdc-cf07826eb720"
      },
      "source": [
        "!pip install -r /content/odsc-ml-drum/colab-requirements.txt -q"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 276kB 19.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.7MB 47.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 276kB 44.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 148.9MB 53kB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 10.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 153kB 55.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 55.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 788kB 48.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 44.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 808kB 52.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 61.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 56.0MB/s \n",
            "\u001b[?25h  Building wheel for PyYAML (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for memory-profiler (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for progress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for strictyaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for uwsgi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbr2w4si9RVl",
        "outputId": "6447ec4a-f6b7-4542-ea80-0e5d57773141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo apt install nginx"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  geoip-database iproute2 libatm1 libgeoip1 libmnl0 libnginx-mod-http-geoip\n",
            "  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter\n",
            "  libnginx-mod-mail libnginx-mod-stream libxtables12 nginx-common nginx-core\n",
            "Suggested packages:\n",
            "  iproute2-doc geoip-bin fcgiwrap nginx-doc ssl-cert\n",
            "The following NEW packages will be installed:\n",
            "  geoip-database iproute2 libatm1 libgeoip1 libmnl0 libnginx-mod-http-geoip\n",
            "  libnginx-mod-http-image-filter libnginx-mod-http-xslt-filter\n",
            "  libnginx-mod-mail libnginx-mod-stream libxtables12 nginx nginx-common\n",
            "  nginx-core\n",
            "0 upgraded, 14 newly installed, 0 to remove and 14 not upgraded.\n",
            "Need to get 3,544 kB of archives.\n",
            "After this operation, 11.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libmnl0 amd64 1.0.4-2 [12.3 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 iproute2 amd64 4.15.0-2ubuntu1.2 [722 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatm1 amd64 1:2.5.1-2build1 [21.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxtables12 amd64 1.6.1-2ubuntu2 [27.9 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 geoip-database all 20180315-1 [2,090 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgeoip1 amd64 1.6.12-1 [71.8 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx-common all 1.14.0-0ubuntu1.7 [37.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-geoip amd64 1.14.0-0ubuntu1.7 [11.2 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-image-filter amd64 1.14.0-0ubuntu1.7 [14.6 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-http-xslt-filter amd64 1.14.0-0ubuntu1.7 [13.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-mail amd64 1.14.0-0ubuntu1.7 [41.8 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libnginx-mod-stream amd64 1.14.0-0ubuntu1.7 [63.7 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx-core amd64 1.14.0-0ubuntu1.7 [413 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 nginx all 1.14.0-0ubuntu1.7 [3,596 B]\n",
            "Fetched 3,544 kB in 1s (4,440 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 14.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libmnl0:amd64.\n",
            "(Reading database ... 144793 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libmnl0_1.0.4-2_amd64.deb ...\n",
            "Unpacking libmnl0:amd64 (1.0.4-2) ...\n",
            "Selecting previously unselected package iproute2.\n",
            "Preparing to unpack .../01-iproute2_4.15.0-2ubuntu1.2_amd64.deb ...\n",
            "Unpacking iproute2 (4.15.0-2ubuntu1.2) ...\n",
            "Selecting previously unselected package libatm1:amd64.\n",
            "Preparing to unpack .../02-libatm1_1%3a2.5.1-2build1_amd64.deb ...\n",
            "Unpacking libatm1:amd64 (1:2.5.1-2build1) ...\n",
            "Selecting previously unselected package libxtables12:amd64.\n",
            "Preparing to unpack .../03-libxtables12_1.6.1-2ubuntu2_amd64.deb ...\n",
            "Unpacking libxtables12:amd64 (1.6.1-2ubuntu2) ...\n",
            "Selecting previously unselected package geoip-database.\n",
            "Preparing to unpack .../04-geoip-database_20180315-1_all.deb ...\n",
            "Unpacking geoip-database (20180315-1) ...\n",
            "Selecting previously unselected package libgeoip1:amd64.\n",
            "Preparing to unpack .../05-libgeoip1_1.6.12-1_amd64.deb ...\n",
            "Unpacking libgeoip1:amd64 (1.6.12-1) ...\n",
            "Selecting previously unselected package nginx-common.\n",
            "Preparing to unpack .../06-nginx-common_1.14.0-0ubuntu1.7_all.deb ...\n",
            "Unpacking nginx-common (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package libnginx-mod-http-geoip.\n",
            "Preparing to unpack .../07-libnginx-mod-http-geoip_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking libnginx-mod-http-geoip (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package libnginx-mod-http-image-filter.\n",
            "Preparing to unpack .../08-libnginx-mod-http-image-filter_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking libnginx-mod-http-image-filter (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package libnginx-mod-http-xslt-filter.\n",
            "Preparing to unpack .../09-libnginx-mod-http-xslt-filter_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking libnginx-mod-http-xslt-filter (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package libnginx-mod-mail.\n",
            "Preparing to unpack .../10-libnginx-mod-mail_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking libnginx-mod-mail (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package libnginx-mod-stream.\n",
            "Preparing to unpack .../11-libnginx-mod-stream_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking libnginx-mod-stream (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package nginx-core.\n",
            "Preparing to unpack .../12-nginx-core_1.14.0-0ubuntu1.7_amd64.deb ...\n",
            "Unpacking nginx-core (1.14.0-0ubuntu1.7) ...\n",
            "Selecting previously unselected package nginx.\n",
            "Preparing to unpack .../13-nginx_1.14.0-0ubuntu1.7_all.deb ...\n",
            "Unpacking nginx (1.14.0-0ubuntu1.7) ...\n",
            "Setting up geoip-database (20180315-1) ...\n",
            "Setting up nginx-common (1.14.0-0ubuntu1.7) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76.)\n",
            "debconf: falling back to frontend: Readline\n",
            "Created symlink /etc/systemd/system/multi-user.target.wants/nginx.service → /lib/systemd/system/nginx.service.\n",
            "Setting up libnginx-mod-http-image-filter (1.14.0-0ubuntu1.7) ...\n",
            "Setting up libgeoip1:amd64 (1.6.12-1) ...\n",
            "Setting up libatm1:amd64 (1:2.5.1-2build1) ...\n",
            "Setting up libxtables12:amd64 (1.6.1-2ubuntu2) ...\n",
            "Setting up libnginx-mod-mail (1.14.0-0ubuntu1.7) ...\n",
            "Setting up libnginx-mod-http-xslt-filter (1.14.0-0ubuntu1.7) ...\n",
            "Setting up libmnl0:amd64 (1.0.4-2) ...\n",
            "Setting up libnginx-mod-http-geoip (1.14.0-0ubuntu1.7) ...\n",
            "Setting up libnginx-mod-stream (1.14.0-0ubuntu1.7) ...\n",
            "Setting up iproute2 (4.15.0-2ubuntu1.2) ...\n",
            "Setting up nginx-core (1.14.0-0ubuntu1.7) ...\n",
            "invoke-rc.d: could not determine current runlevel\n",
            "invoke-rc.d: policy-rc.d denied execution of start.\n",
            "Setting up nginx (1.14.0-0ubuntu1.7) ...\n",
            "Processing triggers for systemd (237-3ubuntu10.42) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAkNyQLWMrlN"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import pickle\n",
        "import datetime\n",
        "\n",
        "## load data\n",
        "\n",
        "df = pd.read_csv('/content/odsc-ml-drum/data/boston_housing.csv')\n",
        "df.head()\n",
        "\n",
        "## set features and target\n",
        "\n",
        "X = df.drop('MEDV', axis=1)\n",
        "y = df['MEDV']\n",
        "\n",
        "## train the model\n",
        "rf = RandomForestRegressor(n_estimators = 20)\n",
        "rf.fit(X,y)\n",
        "\n",
        "## serialize the model\n",
        "\n",
        "with open('/content/odsc-ml-drum/src/custom_model/rf.pkl', 'wb') as pkl:\n",
        "    pickle.dump(rf, pkl)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4p0zDG-VWJP"
      },
      "source": [
        "# Batch Scoring with DRUM\n",
        "<a id=\"setup_complete\"></a>\n",
        "\n",
        "At this point our model has been written to disk and we want to start making predictions with it.  To do this, we'll leverage DRUM and it's ability to natively handle our scikit learn model, all we need to do is tell DRUM where it resides as well as the data we wish to score.  \n",
        "\n",
        "There are a lot of frameworks which DRUM supports nateively, but for those which DRUM doesn't support of these shelf, we'll just need to create some custom hooks so DRUM.  In this example, we'll highlight some very simple custom hooks, and will provide links to more complex examples.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_OOeqEx6hqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1df6dec7-1db3-4668-8c69-b5faa89be80b"
      },
      "source": [
        "%%sh \n",
        "drum score --code-dir /content/odsc-ml-drum/src/custom_model \\\n",
        "--input /content/odsc-ml-drum/data/boston_housing_inference.csv \\\n",
        "--output /content/odsc-ml-drum/data/predictions.csv --target-type regression"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-03 23:19:27.029582: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLQnWJw_MrlU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "9fa50884-f15e-4ab2-872e-a4265f96956c"
      },
      "source": [
        "pd.read_csv(\"/content/odsc-ml-drum/data/predictions.csv\").head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>32.785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.825</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Predictions\n",
              "0       26.020\n",
              "1       22.810\n",
              "2       34.805\n",
              "3       32.785\n",
              "4       35.825"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmS971iweH6t"
      },
      "source": [
        "# Start the inference server locally\n",
        "\n",
        "Batch scoring can be very useful, but the utility DRUM offers does not stop there.  We can also leverage DRUM to serve our model as a RESTful API endpoint.  The only thing that changes is the way we will structure the command - using the `server` mode instead of `score` model.  We'll also need to provide an address which is NOT in use.  \n",
        "\n",
        "When starting the server, we'll use `subprocess.Popen` so we may interact with the server in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7BrHC1gYjHD"
      },
      "source": [
        "import subprocess\n",
        "import requests\n",
        "import pandas as pd\n",
        "from io import BytesIO\n",
        "import yaml\n",
        "import time\n",
        "import os\n",
        "import datarobot as dr\n",
        "from pprint import pprint"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crlRTOHcMrld"
      },
      "source": [
        "run_inference_server = [\"drum\",\n",
        "              \"server\",\n",
        "              \"--code-dir\",\"/content/odsc-ml-drum/src/custom_model\", \n",
        "              \"--address\", \"0.0.0.0:6789\", \n",
        "              \"--show-perf\",\n",
        "              \"--target-type\", \"regression\",\n",
        "              \"--logging-level\", \"info\",\n",
        "              \"--show-stacktrace\",\n",
        "              \"--verbose\",\n",
        "              \"--production\", \n",
        "              \"--max-workers\", \"5\"\n",
        "              ]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWvksr_sYlEr"
      },
      "source": [
        "inference_server = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZfzEEPZ9kZG",
        "outputId": "a9e7b52e-94c9-4f5b-cecb-c295631aea23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!sudo service nginx status"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * nginx is running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peFenY-leJo3"
      },
      "source": [
        "## Ping the Server to make sure it is running"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmh7SRfQVnTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f44525a-9950-491d-ac7d-4dcd28b504f6"
      },
      "source": [
        "## confirm the server is running\n",
        "time.sleep(5) ## snoozing before pinging the server to give it time to actually start\n",
        "print('check status')\n",
        "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check status\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'{\"message\": \"OK\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOsaTgXOeNMG"
      },
      "source": [
        "## Send data to server for inference\n",
        "\n",
        "The request must provide our dataset as form data.  In order to do so, we'll create a simple python function to pass the data over appropriately.  We'll leverage the same function in our simple flask app a little later.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ-sZcHMYmRx"
      },
      "source": [
        "def score(data, port = \"6789\"):\n",
        "    b_buf = BytesIO()\n",
        "    b_buf.write(data.to_csv(index=False).encode(\"utf-8\"))\n",
        "    b_buf.seek(0)\n",
        "  \n",
        "    url = \"http://localhost:{}/predict/\".format(port)\n",
        "    files = [\n",
        "        ('X', b_buf)\n",
        "    ]\n",
        "    response = requests.request(\"POST\", url, files = files, timeout=None, verify=False)\n",
        "    return response"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjdKXUcUWUXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ac2da75-ee37-41c9-bacd-afd0a3f1d362"
      },
      "source": [
        "# %%timeit\n",
        "scoring_data = pd.read_csv(\"/content/odsc-ml-drum/data/boston_housing_inference.csv\")\n",
        "predictions = score(scoring_data).json() ## score entire dataset but only show first 5 records\n",
        "pprint(predictions)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'predictions': [26.02,\n",
            "                 22.81,\n",
            "                 34.805,\n",
            "                 32.785,\n",
            "                 35.825,\n",
            "                 26.335,\n",
            "                 21.78,\n",
            "                 25.885,\n",
            "                 16.16]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a20HW9uMrl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72099122-b93a-4de0-f050-489e5d10e4cc"
      },
      "source": [
        "requests.request(\"GET\", \"http://0.0.0.0:6789/\").content"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'{\"message\": \"OK\"}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG3HHHnR942W",
        "outputId": "5616397e-9c58-4aff-d6e1-a7eff61519db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inference_server.terminate()\n",
        "inference_server.stdout.readlines()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Name: uWSGI\\n',\n",
              " b'Version: 2.0.19.1\\n',\n",
              " b'Summary: The uWSGI server\\n',\n",
              " b'Home-page: https://uwsgi-docs.readthedocs.io/en/latest/\\n',\n",
              " b'Author: Unbit\\n',\n",
              " b'Author-email: info@unbit.it\\n',\n",
              " b'License: GPLv2+\\n',\n",
              " b'Location: /usr/local/lib/python3.6/dist-packages\\n',\n",
              " b'Requires: \\n',\n",
              " b'Required-by: mlpiper\\n',\n",
              " b'Detected REST server mode - this is an advanced option\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m \\x1b[0m\\n',\n",
              " b'\\x1b[32m============================================================\\x1b[0m\\n',\n",
              " b'\\x1b[32mComponent: uwsgi_serving\\x1b[0m\\n',\n",
              " b'\\x1b[32mLanguage:  Python\\x1b[0m\\n',\n",
              " b'\\x1b[32mOutput:\\x1b[0m\\n',\n",
              " b'\\x1b[32m------------------------------------------------------------\\x1b[0m\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXsO0ZQ9wGn",
        "outputId": "1218ba41-c7c2-4d26-d5e3-34be04b55310",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%sh\n",
        "nginx -s stop\n",
        "sudo service nginx status"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * nginx is not running\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM8z8v8cTaqD"
      },
      "source": [
        "# requests.request(\"POST\", \"http://0.0.0.0:6789/shutdown/\").content"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIGQMPjgMrl3"
      },
      "source": [
        "## Value Prop\n",
        "\n",
        "One may ask, what is the benefit to be had here?  Well, first of, there is not need for me to write an api to get the model up and running.  Second, DRUM allows me to abstract the framework away (provided I'm using one that is natively supported, or I can write enough python so that DRUM understands how to hook up to the model.  \n",
        "\n",
        "For example, I could hot swap models as I see fit (see exampels in `./src/other_models`)\n",
        "\n",
        "While we will run through several other frameworks with in `score` you can bet they are supported in `server` mode as well!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHGKKPfNMrl4"
      },
      "source": [
        "#### H2O Mojo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPxTpC-NMrl4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7f0e417-c714-4dbd-c4d6-6052fb9cb73b"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/h2o_mojo/regression --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SLF4J: Failed to load class \"org.slf4j.impl.StaticLoggerBinder\".\n",
            "SLF4J: Defaulting to no-operation (NOP) logger implementation\n",
            "SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.\n",
            "   Predictions\n",
            "0    24.504000\n",
            "1    22.492000\n",
            "2    34.554001\n",
            "3    34.420001\n",
            "4    35.289001\n",
            "5    28.394001\n",
            "6    21.936000\n",
            "7    23.451000\n",
            "8    17.065000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35pX5I94Mrl7"
      },
      "source": [
        "#### Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mz6CNMITMrl7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "241340b8-8463-4c12-b0c0-a90457c560bf"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/python3_keras_joblib --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-02 00:52:35.879918: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator SimpleImputer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator StandardScaler from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator Pipeline from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/base.py:318: UserWarning: Trying to unpickle estimator ColumnTransformer from version 0.23.1 when using version 0.22.2.post1. This might lead to breaking code or invalid results. Use at your own risk.\n",
            "  UserWarning)\n",
            "2020-12-02 00:52:37.171689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
            "2020-12-02 00:52:37.240518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:37.241161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-02 00:52:37.241230: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-02 00:52:37.463018: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-02 00:52:37.606052: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-02 00:52:37.624105: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-02 00:52:37.877985: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-02 00:52:37.928485: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-02 00:52:38.449430: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-02 00:52:38.449676: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.450334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.450885: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-12-02 00:52:38.506473: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
            "2020-12-02 00:52:38.506686: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x247b100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-02 00:52:38.506727: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-12-02 00:52:38.643546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.644281: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x247b2c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-12-02 00:52:38.644330: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2020-12-02 00:52:38.645461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.646036: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2020-12-02 00:52:38.646089: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-02 00:52:38.646129: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "2020-12-02 00:52:38.646153: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\n",
            "2020-12-02 00:52:38.646187: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\n",
            "2020-12-02 00:52:38.646208: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-12-02 00:52:38.646226: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-12-02 00:52:38.646246: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-12-02 00:52:38.646320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.646887: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:38.647366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\n",
            "2020-12-02 00:52:38.650433: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-02 00:52:42.452560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-12-02 00:52:42.452646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \n",
            "2020-12-02 00:52:42.452672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \n",
            "2020-12-02 00:52:42.456481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:42.457220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-12-02 00:52:42.457816: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-12-02 00:52:42.457867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "2020-12-02 00:52:42,665 WARNING tensorflow:  No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
            "2020-12-02 00:52:42.895035: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\n",
            "   Predictions\n",
            "0    23.668932\n",
            "1    23.421118\n",
            "2    31.283525\n",
            "3    33.996525\n",
            "4    33.757940\n",
            "5    28.036715\n",
            "6    20.675852\n",
            "7    19.578413\n",
            "8    19.676756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PsanmxC-Mrl9"
      },
      "source": [
        "#### XGBoost\n",
        "\n",
        "Requires XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myCq6e63Mrl-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be873ac2-fde5-4838-88eb-a92087a521db"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/python3_xgboost --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
            "  defaults = yaml.load(f)\n",
            "2020-12-02 00:52:46.610748: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "   Predictions\n",
            "0    24.541843\n",
            "1    21.260277\n",
            "2    34.018497\n",
            "3    32.569200\n",
            "4    34.248066\n",
            "5    27.282364\n",
            "6    20.803959\n",
            "7    19.645220\n",
            "8    16.968880\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGuTZhCZMrmA"
      },
      "source": [
        "#### DataRobot Codegen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dTPDvBwMrmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575d4721-71df-4083-f264-d5a2d7e9ec35"
      },
      "source": [
        "!drum score --code-dir /content/odsc-ml-drum/src/other_models/dr_codegen --input /content/odsc-ml-drum/data/boston_housing_inference.csv --target-type regression\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   Predictions\n",
            "0    24.258228\n",
            "1    24.258228\n",
            "2    32.451515\n",
            "3    32.451515\n",
            "4    32.451515\n",
            "5    24.258228\n",
            "6    21.078378\n",
            "7    13.107812\n",
            "8    13.107812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3b64jAKbMrmD"
      },
      "source": [
        "# Monitoring Deployments\n",
        "\n",
        "What follows will require a DataRobot account.  You can get a trial account at [https://www.datarobot.com/trial/](https://www.datarobot.com/trial/)\n",
        "\n",
        "Also, JDK 11 or 12 will be required.\n",
        "\n",
        "The main idea: we'll will start an agent service locally.  This agent will be monitoring a spooler.  The spooler could be something as simple as local file system, or a little more realistic like a message broker (pubsub, rabbitmq, sqs).  \n",
        "\n",
        "Once, this agent is spun up locally, we'll enable a few environment variables to let DRUM know that there is an agent present and that it needs to buffer data to defined spool.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tfg4efhHMrmE"
      },
      "source": [
        "## Getting the monitoring agents\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3859XOYMrmE"
      },
      "source": [
        "Currently - have to go in through the [UI](https://app2.datarobot.com/account/developer-tools) to grab the agents "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsnraGL9MrmF"
      },
      "source": [
        "token = \"token\"\n",
        "endpoint = \"https://app2.datarobot.com\"\n",
        "## connect to DataRobot platform with python client. \n",
        "client = dr.Client(token, \"{}/api/v2\".format(endpoint))\n",
        "# mlops_agents_tb = client.get(\"mlopsInstaller\")\n",
        "# with open(\"/content/odsc-ml-drum/mlops-agent.tar.gz\", \"wb\") as f:\n",
        "#     f.write(mlops_agents_tb.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6BU9DbfMrmL"
      },
      "source": [
        "# !tar -xf /content/mlops-agent.tar.gz -C ..\n",
        "!tar -xf /content/datarobot-mlops-agent-6.2.4-399.tar.gz -C ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCvCVHTyMrmO"
      },
      "source": [
        "## Configuring the Agent\n",
        "\n",
        "When we'll configure the agent, we just need to define the DataRobot MLOPS location, our api token.  By default, the agent will expect the data to be spooled on the local file system.  Specifically, the default location will be `/tmp/ta` so we just need to make sure that location exists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmhhI_2_MrmO"
      },
      "source": [
        "!mkdir -p /tmp/ta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDVCJw4qMrmS"
      },
      "source": [
        "agents_dir = \"/content/datarobot-mlops-agent-6.2.4\"\n",
        "with open(r'{}/conf/mlops.agent.conf.yaml'.format(agents_dir)) as file:\n",
        "    documents = yaml.load(file, Loader=yaml.FullLoader)\n",
        "## configure the loaction of the mlops instance with which we'll communcate\n",
        "documents['mlopsUrl'] = endpoint\n",
        "# Set your API token\n",
        "documents['apiToken'] = token\n",
        "## write the configuration back to disk\n",
        "with open('../{}/conf/mlops.agent.conf.yaml'.format(agents_dir), \"w\") as f:\n",
        "    yaml.dump(documents, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdaHl8XGMrmU"
      },
      "source": [
        "## Start the Agent Service\n",
        "\n",
        "Checking to make sure we can start up the agents service.  \n",
        "\n",
        "This will require a JDK - tested with 11 and 12"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXqlGPhVMrmU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6d91314-67f9-4061-efff-ce22238993bf"
      },
      "source": [
        "## run agents service\n",
        "subprocess.call(\"{}/bin/start-agent.sh\".format(agents_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ED-Oqh8MrmX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77b094ad-cc66-4d76-d107-fc0d0d0147a5"
      },
      "source": [
        "## check status\n",
        "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "print(check.stdout.readlines())\n",
        "check.terminate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'DataRobot MLOps-Agent is running as a service.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyOhPs-6MrmZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f479490-07a8-4fb4-a6ad-e23a3aff7797"
      },
      "source": [
        "## check log to see that the agent connected to DR MLOps\n",
        "check = subprocess.Popen([\"cat\", \"../{}/logs/mlops.agent.log\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "for line in check.stdout.readlines():\n",
        "    print(line)\n",
        "check.terminate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "b'2020-11-16 19:01:02,449 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Found spooler of type FILESYSTEM\\n'\n",
            "b'2020-11-16 19:01:02,452 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting directory = /tmp/ta\\n'\n",
            "b'2020-11-16 19:01:02,453 INFO  com.datarobot.mlops.agent.config.channels.YamlBuilder        [] - Setting CHANNEL_NAME = filesystem\\n'\n",
            "b\"2020-11-16 19:01:03,699 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.22'\\n\"\n",
            "b\"2020-11-16 19:01:04,258 INFO  com.datarobot.mlops.common.client.MLOpsClient                [] - DataRobot Server API Version found: '2.22'\\n\"\n",
            "b\"2020-11-16 19:01:04,259 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot server at 'https://app2.datarobot.com' is reachable.\\n\"\n",
            "b'2020-11-16 19:01:04,259 INFO  com.datarobot.mlops.agent.Agent                              [] - DataRobot Monitoring Agent will process 100 records at a time at most.\\n'\n",
            "b'2020-11-16 19:01:04,261 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Creating new agent channel\\n'\n",
            "b'2020-11-16 19:01:04,261 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initializing agent channel\\n'\n",
            "b'2020-11-16 19:01:04,300 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Initialized\\n'\n",
            "b'2020-11-16 19:01:04,302 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Listing channels:\\n'\n",
            "b'\\tChannel Name: filesystem, Channel Type: FILESYSTEM\\n'\n",
            "b'\\n'\n",
            "b'2020-11-16 19:01:04,304 INFO  com.datarobot.mlops.agent.AgentRunner                        [] - Running agent as service process pid and hostname [1239@ab84dd6ef507]\\n'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpKEu8LsMrmb"
      },
      "source": [
        "## DataRobot MLOps - Deploying External Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzhVEIIhMrmb"
      },
      "source": [
        "To communication with DataRobot MLOps, with need to MLOps python client installed which came in the downloaded tarball"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDk1PZv6Mrmc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5ac2e1-bc94-423a-ef78-d0501e831c34"
      },
      "source": [
        "!pip install /content/datarobot-mlops-*/lib/datarobot_mlops-*.whl -q"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 112kB 13.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 23.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.9MB 18.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 204kB 55.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 552kB 48.3MB/s \n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U73bULPOMrme"
      },
      "source": [
        "from datarobot.mlops.mlops import MLOps\n",
        "from datarobot.mlops.common.enums import OutputType\n",
        "from datarobot.mlops.connected.client import MLOpsClient\n",
        "from datarobot.mlops.common.exception import DRConnectedException\n",
        "from datarobot.mlops.constants import Constants"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnC0LZIFMrmg"
      },
      "source": [
        "DEPLOYMENT_NAME=\"Boston Housing Prices PGH Data Science Meetup\"\n",
        "TRAINING_DATA = '/content/odsc-ml-drum/data/boston_housing.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZO6QToQMrmi"
      },
      "source": [
        "model_info = {\n",
        "        \"name\": \"Boston Housing Pricins\",\n",
        "        \"modelDescription\": {\n",
        "            \"description\": \"prediction price of home\"\n",
        "        },\n",
        "        \"target\": {\n",
        "            \"type\": \"Regression\",\n",
        "            \"name\": \"MEDV\",\n",
        "        }\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz3coM_7Mrml",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02d52f9d-3563-407f-d29d-21245a12553d"
      },
      "source": [
        "# Create connected client\n",
        "mlops_client = MLOpsClient(endpoint, token)\n",
        "\n",
        "# Add training_data to model configuration\n",
        "print(\"Uploading training data - {}. This may take some time...\".format(TRAINING_DATA))\n",
        "dataset_id = mlops_client.upload_dataset(TRAINING_DATA)\n",
        "print(\"Training dataset uploaded. Catalog ID {}.\".format(dataset_id))\n",
        "model_info[\"datasets\"] = {\"trainingDataCatalogId\": dataset_id}\n",
        "\n",
        "# Create the model package\n",
        "print('Create model package')\n",
        "model_pkg_id = mlops_client.create_model_package(model_info)\n",
        "model_pkg = mlops_client.get_model_package(model_pkg_id)\n",
        "model_id = model_pkg[\"modelId\"]\n",
        "\n",
        "# Deploy the model package\n",
        "print('Deploy model package')\n",
        "deployment_id = mlops_client.deploy_model_package(model_pkg[\"id\"],\n",
        "                                                            DEPLOYMENT_NAME)\n",
        "\n",
        "# Enable data drift tracking\n",
        "print('Enable feature drift')\n",
        "enable_feature_drift = TRAINING_DATA is not None\n",
        "mlops_client.update_deployment_settings(deployment_id, target_drift=True,\n",
        "                                                  feature_drift=enable_feature_drift)\n",
        "_ = mlops_client.get_deployment_settings(deployment_id)\n",
        "\n",
        "print(\"\\nDone.\")\n",
        "print(\"DEPLOYMENT_ID=%s, MODEL_ID=%s\" % (deployment_id, model_id))\n",
        "\n",
        "DEPLOYMENT_ID = deployment_id\n",
        "MODEL_ID = model_id"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uploading training data - /content/odsc-ml-drum/data/boston_housing.csv. This may take some time...\n",
            "Training dataset uploaded. Catalog ID 5fb2cc94e3a7e9072ed463fa.\n",
            "Create model package\n",
            "Deploy model package\n",
            "Enable feature drift\n",
            "\n",
            "Done.\n",
            "DEPLOYMENT_ID=5fb2ccba6a2cd70255b0fa2c, MODEL_ID=5fb2ccb82133930df77dea02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k96KiRFiMrmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e96f12e9-2d5e-49b2-87dd-d3b3a6e4aade"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "link = \"{}/deployments/{}/overview\".format(endpoint,deployment_id)\n",
        "# display(HTML(\"\"\"<a href=\"{link}\">{link}</a>\"\"\".format( link=link )))\n",
        "print(link)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://app2.datarobot.com/deployments/5fb2ccba6a2cd70255b0fa2c/overview\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_sIji-jleSr"
      },
      "source": [
        "# Adding Monitoring with MLOps Monitoring Agents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbbfRWU1Mrmp"
      },
      "source": [
        "## Monitoring With DRUM\n",
        "\n",
        "There are a few addition parameters we should set for the command line utility, or we may just create environment variables, and allow the drum utility to pick up the details from there.  \n",
        "\n",
        "```\n",
        "  --monitor             Monitor predictions using DataRobot MLOps. True or\n",
        "                        False. (env: MONITOR).Monitoring can not be used in\n",
        "                        unstructured mode.\n",
        "  --deployment-id DEPLOYMENT_ID\n",
        "                        Deployment id to use for monitoring model predictions\n",
        "                        (env: DEPLOYMENT_ID)\n",
        "  --model-id MODEL_ID   MLOps model id to use for monitoring predictions (env:\n",
        "                        MODEL_ID)\n",
        "  --monitor-settings MONITOR_SETTINGS\n",
        "                        MLOps setting to use for connecting with the MLOps\n",
        "                        Agent (env: MONITOR_SETTINGS)\n",
        "```\n",
        "For today, we'll set environment variables to add monitoring. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uu23gamNMrmq"
      },
      "source": [
        "os.environ[\"MONITOR\"] = \"True\"\n",
        "os.environ[\"DEPLOYMENT_ID\"] = deployment_id\n",
        "os.environ[\"MODEL_ID\"] = model_id\n",
        "os.environ[\"MONITOR_SETTINGS\"] = \"spooler_type=filesystem;directory=/tmp/ta;max_files=5;file_max_size=1045876000\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gs6kK8PKMrmr"
      },
      "source": [
        "run_inference_server = [\"drum\",\n",
        "              \"server\",\n",
        "              \"--code-dir\",\"/content/odsc-ml-drum/src/custom_model\", \n",
        "              \"--address\", \"0.0.0.0:43210\", \n",
        "              \"--show-perf\",\n",
        "              \"--target-type\", \"regression\",\n",
        "              \"--logging-level\", \"info\",\n",
        "              \"--show-stacktrace\",\n",
        "#               \"--verbose\"\n",
        "              ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkbK6OKbMrmt"
      },
      "source": [
        "inference_server_with_monitoring = subprocess.Popen(run_inference_server, stdout=subprocess.PIPE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72S5ic_sMrmv"
      },
      "source": [
        "predictions = score(\n",
        "    pd.read_csv(\"/content/odsc-ml-drum/data/boston_housing.csv\").drop([\"MEDV\"],axis=1).head(100),\n",
        "    \"43210\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQA_TvN3Mrmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "a9227d65-2a1e-4e81-9cd4-39fb731165c8"
      },
      "source": [
        "pd.DataFrame(predictions.json()).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>26.345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22.180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>34.640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>33.845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35.320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   predictions\n",
              "0       26.345\n",
              "1       22.180\n",
              "2       34.640\n",
              "3       33.845\n",
              "4       35.320"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LPPW7qsMrm0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "965afe17-6fb2-4723-9f46-d6dd7a08cd4e"
      },
      "source": [
        "requests.post(\"http://localhost:43210/shutdown/\").content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'Server shutting down...'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDZ48oQFMrm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa615c8c-406a-437a-d45a-0477817b7c2a"
      },
      "source": [
        "subprocess.call(\"../{}/bin/stop-agent.sh\".format(agents_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAM_HvAiMrm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e84f6932-2180-4838-ceb9-2765d75bcbc5"
      },
      "source": [
        "## check that agent is stopped \n",
        "check = subprocess.Popen([\"../{}/bin/status-agent.sh\".format(agents_dir)], stdout=subprocess.PIPE)\n",
        "print(check.stdout.readlines())\n",
        "check.terminate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'DataRobot MLOps-Agent is not running as a service.\\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6o_bqcGCMrnA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4354c2cd-b116-4df4-a498-e64e208cd1e0"
      },
      "source": [
        "deployment = dr.Deployment.get(deployment_id)\n",
        "deployment.get_service_stats()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ServiceStats(5fb2ccb82133930df77dea02 | 2020-11-09 20:00:00+00:00 - 2020-11-16 20:00:00+00:00)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6m5-5VUIMrnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc5f60d0-c598-4167-9833-4dcaada19478"
      },
      "source": [
        "service_stats = deployment.get_service_stats()\n",
        "service_stats.metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cacheHitRatio': 0,\n",
              " 'executionTime': 15.6660079956055,\n",
              " 'medianLoad': 0,\n",
              " 'numConsumers': 1,\n",
              " 'peakLoad': 1,\n",
              " 'responseTime': 0,\n",
              " 'serverErrorRate': 0,\n",
              " 'slowRequests': 0,\n",
              " 'totalPredictions': 100,\n",
              " 'totalRequests': 1,\n",
              " 'userErrorRate': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Vff7CRdcbhb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}